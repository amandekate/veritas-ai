ğŸ•µï¸â€â™€ï¸ Veritas AI â€” Multimodal Fake News Detection

A multimodal fake news detection system that analyzes textual headlines and associated images to classify news as Real or Fake.
The system combines predictions from a text model (BERT) and an image model (ResNet50) using late fusion with configurable weights.

ğŸ¯ Why it matters: Fake news often appears credible in one modality (text or image). This system explicitly handles that weakness.

ğŸ“Œ Project Overview

Fake news often exploits both misleading text and deceptive images. Single-modal systems fail when one modality appears legitimate.

This project addresses that gap by:

Analyzing headline text using a transformer-based NLP model

Analyzing news images using a CNN-based vision model

Combining predictions using late fusion

Allowing dynamic control of modality importance via UI

ğŸ§  Architecture
Text Modality

Model: BERT (fine-tuned)

Input: News headline

Output: Probability of REAL news

Image Modality

Model: ResNet50 (fine-tuned)

Input: News image

Output: Probability of REAL news

Fusion Strategy

Late Fusion (Weighted Average)

Final score:
w_text Ã— P_text(real) + w_image Ã— P_image(real)

Weights always sum to 1.0 and are adjustable in real time

ğŸ–¥ï¸ Application Interface

The system is deployed as a Streamlit web application with:

Text input for news headline

Image upload for related news image

Slider to control text vs image importance

Clear verdict display: REAL or FAKE

Confidence score with per-modality breakdown

ğŸ“‚ Project Structure
â”œâ”€â”€ app.py                      # Streamlit application
â”œâ”€â”€ final_main.ipynb            # Training & evaluation notebook
â”œâ”€â”€ final_text_model.h5         # Trained BERT text model
â”œâ”€â”€ final_image_model.keras     # Trained ResNet50 image model
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # Project documentation

## ğŸ”— Pretrained Models

Due to GitHub file size limitations, the pretrained models used in this project are hosted on Google Drive.

ğŸ“ **Google Drive Folder (Download Models):**  
https://drive.google.com/drive/folders/19ZIiC0GIu7ZuZyW1QxMYLna2PURa0WGD?usp=sharing

### Contents
- **final_text_model.h5** â€” Fine-tuned BERT text model
- **final_image_model.keras** â€” Fine-tuned ResNet50 image model

After downloading, place both files in the project root directory before running the Streamlit app.

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/veritas-ai.git
cd veritas-ai

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the Application
streamlit run app.py

ğŸ”¬ Model Details
Text Model

Tokenizer: bert-base-uncased

Input length: 64 tokens

Output: Binary classification (REAL / FAKE)

Image Model

Input size: 160 Ã— 160 RGB

Preprocessing: ResNet50 preprocessing

Output: Binary classification (REAL / FAKE)

ğŸ“Š Output Explanation

Final Verdict: REAL or FAKE

Confidence Score: Probability of the predicted class

BERT Score: Contribution from text modality

ResNet Score: Contribution from image modality

This breakdown ensures interpretability, not just blind prediction.

ğŸš« Limitations

Being transparent:

No cross-modal attention (modalities processed independently)

Performance depends on dataset quality

Only headline text is used (not full articles)

Fusion weights are manually controlled, not learned

These constraints are intentional and clearly scoped.

ğŸš€ Future Improvements

Learned fusion instead of manual weights

Cross-modal attention mechanisms

Full article text analysis

Explainability using Grad-CAM and attention visualization

Real-time news scraping integration

ğŸ‘¨â€ğŸ’» Contributors

Aman Dekate

Rutwik Dakhore

Team Members

ğŸ“œ License

This project is intended for academic and educational use.